# =================== Ingestion (src/ml/ingest/import_raw_data.py) ===================
# Nom du CSV brut déjà présent sous ./data/raw (monté en volume)
RAW_FILE_NAME="comptage-velo-donnees-compteurs-2024-2025_Enriched_ML-ready_data.csv"

# Filtrage du compteur (voir colonnes du CSV)
SITE="Totem 73 boulevard de Sébastopol"
ORIENTATION="N-S"

# Plage de pourcentages à garder (0–100)
RANGE_START=0.0
RANGE_END=75.0

# Dossier logique pour chaîner toute la run
SUB_DIR="Sebastopol_N-S_mlops"
INTERIM_NAME="initial.csv"

# =================== Features (src/ml/features/build_features.py) =================
# Nom du CSV de sortie après features
PROCESSED_NAME="initial_with_feats.csv"

# =================== Modélisation (src/ml/models/train_and_predict.py) ===========
# Hyperparamètres principaux + split temporel
AR=7
MM=1
ROLL=24
TEST_RATIO=0.25
GRID_ITER=0

# =================== API (src/api/main.py) =================
# Nom du répertoire contenant les prédictions finales 
DATA_FINAL_ROOT="/app/data/final"

# =================== MLflow & MinIO (override optionnel) ========================
MLFLOW_TRACKING_URI="http://mlflow-server:5000"
MLFLOW_S3_ENDPOINT_URL="http://mlflow-minio:9000"
AWS_ACCESS_KEY_ID="minio"
AWS_SECRET_ACCESS_KEY="minio123"
AWS_DEFAULT_REGION="us-east-1"

# =================== Airflow (override optionnel) ========================
AIRFLOW_UID=1000 # airflow uses current user (id -u)
AIRFLOW_GID=1001 # airflow uses docker group (getent group docker | cut -d: -f3)
AIRFLOW_WWW_USER_USERNAME=airflow
AIRFLOW_WWW_USER_PASSWORD=airflow

# =================== Grafana (override optionnel) ========================
GRAFANA_ADMIN_USER=grafana
GRAFANA_ADMIN_PASSWORD=grafana

# =================== Monitoring ===================
PUSHGATEWAY_ADDR="monitoring-pushgateway:9091"
DISABLE_METRICS_PUSH=0

# =================== Divers ======================================================
# Fuseau horaire utile aux conversions locales
TZ="Europe/Paris"