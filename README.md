# ğŸš² Cyclist Traffic MLOPS Project

[![CI Main](https://github.com/zheddhe/avr25-mle-trafic-cycliste/actions/workflows/ci_main.yml/badge.svg)](https://github.com/zheddhe/avr25-mle-trafic-cycliste/actions)
[![CI Branch](https://github.com/zheddhe/avr25-mle-trafic-cycliste/actions/workflows/ci_branch.yml/badge.svg)](https://github.com/zheddhe/avr25-mle-trafic-cycliste/actions)

> A machine learning pipeline to provide bike traffic prediction in Paris.  
> Developed as part of the April 2025 Machine Learning Engineering (MLE) full training program.

---

## ğŸ§­ Overview

This project implements a full machine learning and MLOps pipeline in three main stages:

### 1. ğŸ“ Data Product Management

- Define business goals
- Scope the data lifecycle

### 2. ğŸ“Š Data Science

- Data collection and preprocessing
- Model development and evaluation
- Time series prediction

### 3. âš™ï¸ MLOps

- Reproducibility and continuous testing
- Containerization with micro services
- Security awareness
- Monitoring and orchestration
- Scalability

## ğŸ“– Project documentation

- [Data exploration report](https://docs.google.com/spreadsheets/d/1tlDfN-8h9XTJAoKY0zAzmgrJqX90ZAeer48mFxZ_IQg/edit?usp=drive_link)
- [Data processing and modelization report](https://docs.google.com/document/d/1vpRAWaIRX5tjIalEjGLTIjNqwEh1z1kXRZjJA9cgeWo/edit?usp=drive_link)

---

## ğŸ§± Project Structure

``` text
avr25-mle-trafic-cycliste/
â”œâ”€â”€ LICENSE             <- MIT license
â”œâ”€â”€ README.md           <- This top-level README for developers using this project
â”œâ”€â”€ flake8              <- Linter configuration rules
â”œâ”€â”€ pyproject.toml      <- Python dev project configuration
â”œâ”€â”€ uv.lock             <- UV frozen configuration of the dev env
â”œâ”€â”€ noxfile.py          <- NOX dev session (build/clean)
â”œâ”€â”€ data                <- Data storage
â”‚Â Â  â”œâ”€â”€ raw             <- The original, immutable data dump (e.g. from external sources)
â”‚Â Â  â”œâ”€â”€ processed       <- Intermediate data that has been transformed (e.g. enriched)
â”‚Â Â  â””â”€â”€ final           <- data in final stage (e.g. predictions)
â”œâ”€â”€ logs                <- Logs from training and predicting
â”‚Â Â  â””â”€â”€...
â”œâ”€â”€ models              <- Trained and serialized models including their best params and transformers
â”‚Â Â  â””â”€â”€...
â”œâ”€â”€ notebooks           <- Jupyter notebooks. Naming convention : number, author initials, short
â”‚Â Â  â””â”€â”€...                 description with `-` delimitor (e.g. `1.0-jqp-initial-data-exploration`)
â”œâ”€â”€ references          <- Data dictionaries, manuals, and all other explanatory materials
â”‚Â Â  â””â”€â”€...
â”œâ”€â”€ reports             <- Generated analysis as HTML, PDF, LaTeX, etc...
â”‚Â Â  â””â”€â”€ figures         <- Generated graphics and figures to be used in reporting
â”‚Â Â      â””â”€â”€...
â”œâ”€â”€ src/                <- All Source code used in this project
â”‚   â”œâ”€â”€ api/            <- Service FastAPI (lecture des prÃ©dictions)
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ ml/             <- machine learning pipeline
â”‚   â”‚   â”œâ”€â”€ data        <- Scripts to collect intial raw data or generate new daily one
â”‚   â”‚   â”‚   â”œâ”€â”€ data_utils.py
â”‚   â”‚   â”‚   â””â”€â”€ import_raw_data.py
â”‚   â”‚   â”œâ”€â”€ features    <- Scripts to turn raw data into modeling ready data
â”‚   â”‚   â”‚   â”œâ”€â”€ features_utils.py
â”‚   â”‚   â”‚   â””â”€â”€ build_features.py
â”‚   â”‚   â”œâ”€â”€ models      <- Scripts to train models and calculate predictions in batch
â”‚   â”‚   â”‚   â”œâ”€â”€ models_utils.py
â”‚   â”‚   â”‚   â””â”€â”€ train_and_predict.py
â”‚   â””â”€â”€ shared/         <- Shared services
â”‚       â””â”€â”€ logger.py
â”œâ”€â”€ docker/             <- container architecture
â”‚   â”œâ”€â”€ dev/            <- dev architecture
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ ml/
â”‚   â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”œâ”€â”€ prod/           <- production architecture
â”‚   â”‚   â””â”€â”€...       
â””â”€â”€ tests/              <- Unit tests (pytest for src source code)
```

---

## âš™ï¸ Installation

### ğŸ”§ Initial Setup (One-time bootstrap)

The build environment initialization requires python, pipx, NOX, UV as a Bootstrap.

```bash
# check python is here (if not install it manually depending on your OS)
python --version 
# install pipx and publish it into the PATH  
python -m pip install --upgrade pip
python -m pip install --user pipx
pipx ensurepath
# install NOX (session manager like a MAKE multi OS) and UV (fast virtual env back end)
pipx install nox uv
```

### ğŸ”§ Repository cloning and DVC setup (One-time init)

Please refer to the Dagshub remote setup actions depending on your preference to collect:

- Git cloning actions (for example)

```bash
git clone https://github.com/zheddhe/avr25-mle-trafic-cycliste.git
```

- DVC setup actions (for example)

```bash
dvc remote add origin s3://dvc
dvc remote modify origin endpointurl https://dagshub.com/zheddhe/avr25-mle-trafic-cycliste.s3

dvc remote modify origin --local access_key_id [...]
dvc remote modify origin --local secret_access_key [...]
```

## ğŸš€ Day-to-day Usage

```bash
# Rebuild a complete virtual dev env (and trigger flake8 and pytest)
nox -s build

# Activate the virtual env in command line (based on your OS)
.nox\build\Scripts\activate.bat # cmd shell windows only
# or
source .nox/build/bin/activate # cmd shell Mac/Linux only

# [Optional] Clean all project generated file and all virtual envs (build included)
nox -s cleanall

# [Dev without container only] execute the dvc pipeline
dvc repro

# [Dev without container only] launch the data API (find a free port on your system)
uvicorn src.api.main:app --reload --port 10000
# the API will be available at http://localhost:10000/docs
```

---

## ğŸ§ª Testing and Continuous Integration

Tests are executed using `pytest`, including:

- âœ… Unit tests for each modules (in `tests/`)  

CI workflows are handled by GitHub Actions:

- `ci_main.yml`: runs on every push or pull request to the `main` branch  
- `ci_branch.yml`: runs on every push to any other branch

---

## ğŸ‘¥ Collaborative branch workflow

Based on [jbenet/simple-git-branching-model.md](https://gist.github.com/jbenet/ee6c9ac48068889b0912) and illustrated below

- Create branch per story/bugfix and merge them with pull requests afterward
- Tag stable versions ideally after each story/bugfix successfull merge

![Collaborative branch workflow](references/collaborative_branch_workflow.drawio.png)

---

## ğŸ‘¥ Contributors

- RÃ©my Canal â€“ [@remy.canal](mailto:remy.canal@live.fr)  
- Elias Djouadi â€“ [@elias.djouadi](mailto:elias.djouadi@gmail.com)
- KoladÃ© Houessou â€“ [@kolade.houessou](mailto:koladehouessou@gmail.com)
