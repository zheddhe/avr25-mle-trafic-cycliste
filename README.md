# üö≤ Cyclist Traffic MLOPS Project

[![CI Main](https://github.com/zheddhe/avr25-mle-trafic-cycliste/actions/workflows/ci_main.yml/badge.svg)](https://github.com/zheddhe/avr25-mle-trafic-cycliste/actions)
[![CI Branch](https://github.com/zheddhe/avr25-mle-trafic-cycliste/actions/workflows/ci_branch.yml/badge.svg)](https://github.com/zheddhe/avr25-mle-trafic-cycliste/actions)

> A machine learning pipeline to provide bike traffic prediction in Paris.  
> Developed as part of the April 2025 Machine Learning Engineering (MLE) full training program.

## üß≠ Overview

This project implements a full machine learning and MLOps pipeline in three main stages:

### 1. üìê Data Product Management

- Define business goals
- Scope the data lifecycle

### 2. üìä Data Science

- Data collection and preprocessing
- Model development and evaluation
- Time series prediction

### 3. ‚öôÔ∏è MLOps

- Reproducibility and continuous testing
- Containerization with micro services
- Security awareness
- Monitoring and orchestration
- Scalability

The MLOps architecture we've designed focus on interactions between components in order to achieve our main business case where an external user
access daily refreshed predictions of the biking trafic.

[![MLOps Architecture v2](references/Architecture_MLOps_v2.drawio.png)](https://drive.google.com/file/d/12olpeXpeOF2-UgBSf1h_LhjRVfG8t3KB/view?usp=drive_link)

## üß≠ Project organization

### 1. üìñ External Documentation

- [Data exploration report](https://docs.google.com/spreadsheets/d/1tlDfN-8h9XTJAoKY0zAzmgrJqX90ZAeer48mFxZ_IQg/edit?usp=drive_link)
- [Data processing and modelization report](https://docs.google.com/document/d/1vpRAWaIRX5tjIalEjGLTIjNqwEh1z1kXRZjJA9cgeWo/edit?usp=drive_link)

### 2. üó∫Ô∏è GitHub Dashboards

- [Roadmap](https://github.com/users/zheddhe/projects/6/views/2)
- [Current Iteration](https://github.com/users/zheddhe/projects/6/views/3)

### 3. üë• Branch Workflow

Based on [jbenet/simple-git-branching-model.md](https://gist.github.com/jbenet/ee6c9ac48068889b0912) and illustrated below

- Create branch per story/bugfix and merge them with pull requests afterward
- Tag stable versions ideally after each story/bugfix successfull merge

[![Collaborative branch workflow](references/Branch_Workflow.drawio.png)](https://drive.google.com/file/d/1ctszHKpKDMjhGkC_sdQ3RD8RGAonb967/view?usp=drive_link)

### 4. üìä MLflow

This project keep a registry of **metrics**, **params** and training and prediction **artefacts**
(sklearn pipeline, auto-regressive transformer, splits train test and pr√©dictions, metrics and hyperparams)
in **MLflow**.

### 5. üß± Project Structure

``` text
avr25-mle-trafic-cycliste/
‚îú‚îÄ‚îÄ LICENSE             <- MIT license
‚îú‚îÄ‚îÄ README.md           <- This top-level README for developers using this project
‚îú‚îÄ‚îÄ flake8              <- Linter configuration rules
‚îú‚îÄ‚îÄ pyproject.toml      <- Python dev project configuration
‚îú‚îÄ‚îÄ uv.lock             <- UV frozen configuration of the dev env
‚îú‚îÄ‚îÄ noxfile.py          <- NOX dev session (build/clean)
‚îú‚îÄ‚îÄ data                <- Data storage
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ raw             <- The original, immutable data dump (e.g. from external sources)
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ interim         <- Intermediate data extracted from raw (e.g. specialized for a goal)
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ processed       <- Processed data that has been transformed (e.g. enriched with feats)
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ final           <- Final stage data (e.g. train/test and predictions)
‚îú‚îÄ‚îÄ logs                <- Logs from training and predicting
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ...
‚îú‚îÄ‚îÄ models              <- Trained and serialized models including their best params and transformers
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ...
‚îú‚îÄ‚îÄ references          <- Data dictionaries, manuals, and all other explanatory materials
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ...
‚îú‚îÄ‚îÄ src/                <- All Source code used in this project
‚îÇ   ‚îú‚îÄ‚îÄ api/            <- Service FastAPI (lecture des pr√©dictions)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.py
‚îÇ   ‚îî‚îÄ‚îÄ ml/             <- machine learning pipeline
‚îÇ       ‚îú‚îÄ‚îÄ data        <- Scripts to collect intial raw data or generate new daily one
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ data_utils.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ import_raw_data.py
‚îÇ       ‚îú‚îÄ‚îÄ features    <- Scripts to turn raw data into modeling ready data
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ features_utils.py
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ build_features.py
‚îÇ       ‚îî‚îÄ‚îÄ models      <- Scripts to train models and calculate predictions in batch
‚îÇ           ‚îú‚îÄ‚îÄ models_utils.py
‚îÇ           ‚îî‚îÄ‚îÄ train_and_predict.py
‚îú‚îÄ‚îÄ docker/             <- container architecture
‚îÇ   ‚îú‚îÄ‚îÄ dev/            <- dev architecture
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ml/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ prod/           <- production architecture
‚îÇ       ‚îî‚îÄ‚îÄ...       
‚îî‚îÄ‚îÄ tests/              <- Unit tests (pytest for src source code)
```

## ‚öôÔ∏è Installation

### üîß Initial Setup (One-time bootstrap)

The build environment initialization requires python, pipx, NOX, UV as a Bootstrap.

```bash
# check python is here (if not install it manually depending on your OS)
python --version 
# install pipx and publish it into the PATH  
python -m pip install --upgrade pip
python -m pip install --user pipx
pipx ensurepath
# install NOX (session manager like a MAKE multi OS) and UV (fast virtual env back end)
pipx install nox uv
```

### üîß Repository cloning and DVC setup (One-time init)

Please refer to the Dagshub remote setup actions depending on your preference to collect:

- Git cloning actions (for example)

```bash
git clone https://github.com/zheddhe/avr25-mle-trafic-cycliste.git
```

- DVC setup actions (for example)

```bash
dvc remote add origin s3://dvc
dvc remote modify origin endpointurl https://dagshub.com/zheddhe/avr25-mle-trafic-cycliste.s3

dvc remote modify origin --local access_key_id [...]
dvc remote modify origin --local secret_access_key [...]
```

## üöÄ Day-to-day Usage

```bash
# Rebuild a complete virtual dev env (and trigger flake8 and pytest)
nox -s build

# Activate the virtual env in command line (based on your OS)
# Windows cmd
.nox\build\Scripts\activate.bat 
# Mac/Linux shell
source .nox/build/bin/activate

# [Optional] Clean all project generated file and all virtual envs (build included)
nox -s cleanall

# [Dev without container only] execute the dvc pipeline
dvc repro

# [Dev without container only] launch the data API (find a free port on your system)
uvicorn src.api.main:app --reload --port 10000
# the API will be available at http://localhost:10000/docs

# Configure Dagshub MLflow serveur through environment variable (based on your OS)
# Windows cmd
set MLFLOW_TRACKING_URI=https://dagshub.com/zheddhe/avr25-mle-trafic-cycliste.mlflow 
set MLFLOW_TRACKING_USERNAME=<DagsHub ACCOUNT>
set MLFLOW_TRACKING_PASSWORD=<DagHhub TOKEN (preferrably over a personnal password...)>
# Mac/Linux shell
export MLFLOW_TRACKING_URI=https://dagshub.com/zheddhe/avr25-mle-trafic-cycliste.mlflow
export MLFLOW_TRACKING_USERNAME=<DagsHub ACCOUNT>
export MLFLOW_TRACKING_PASSWORD=<DagsHub TOKEN (preferrably over a personnal password...)>

# Configure Local MLflow dockerized server through environment variables (based on your OS)
# Windows cmd
set MLFLOW_TRACKING_URI=http://127.0.0.1:5000
set MLFLOW_S3_ENDPOINT_URL=http://127.0.0.1:9000
# Mac/Linux shell
export MLFLOW_TRACKING_URI=http://127.0.0.1:5000
export MLFLOW_S3_ENDPOINT_URL=http://127.0.0.1:9000

```

In fully dockerized MLOps local environment, we'll switch an .env.local file configuration with the following content:

```text
MLFLOW_TRACKING_URI=http://127.0.0.1:5000
MLFLOW_S3_ENDPOINT_URL=http://127.0.0.1:9000
```

Then the docker composition will assemble all dockers with the .env.local context:

```bash
# init and launch all the dockers containers
docker compose --env-file .env.local up -d --force-recreate
```

## üß™ Testing and Continuous Integration

Tests are executed using `pytest`, including:

- ‚úÖ Unit tests for each modules (in `tests/`)  

CI workflows are handled by GitHub Actions:

- `ci_main.yml`: runs on every push or pull request to the `main` branch  
- `ci_branch.yml`: runs on every push to any other branch

## üë• Contributors

- R√©my Canal ‚Äì [@remy.canal](mailto:remy.canal@live.fr)  
- Elias Djouadi ‚Äì [@elias.djouadi](mailto:elias.djouadi@gmail.com)
- Kolad√© Houessou ‚Äì [@kolade.houessou](mailto:koladehouessou@gmail.com)
